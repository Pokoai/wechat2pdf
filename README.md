# wechat2pdf
> 目标：将微信公众号「历史文章」批量导出为 pdf 文档

工具：python + pdfkit（wkhtmltopdf） + requests + BeautifulSoup4 + re

**目前版本：**

1. 文章链接手动提供
2. 未实现批量功能，仅实现单篇文章的导出

**后续改进：**

1. 仅提供公众号名称或其他信息，自动获取公众号全部历史文章链接等信息，并存储到 csv 文件 或数据库中；
2. 用 pyqt 封装起来，实现一键下载；


## album2pdf
> 目标：将微信公众号「合集文章」批量导出为 pdf 文档

**目前版本：**

1. 提供合集链接，即可批量下载；
2. 可以实现多个合集的批量下载；
3. 利用各个合集 data.txt 数据库文件 和 更新日志.txt 文件对比，初步实现增量下载功能；
4. 利用 Windows 系统的定时任务功能，实现每天 5 次的增量更新；
5. 邮件通知功能开发完成；

效果展示：
![](https://img.arctee.cn/one/202207191515970.png)

![](https://img.arctee.cn/one/202207191516771.png)

**后续改进：**

1. ~~补充一个需求：增量下载。目前运行程序就会全部重新下载一遍（伪更新），既浪费资源，又会覆盖掉阅读时做的标注。~~

    ~~我阅读习惯是全部下载后打印出来阅读，所以影响不大。如果是在电脑上直接阅读 pdf 的话，增量下载功能就特别重要了。~~
    
    ~~如何实现这个功能需要思考下，比如对比新旧 data.txt 内容，~~或者有更好的方法，欢迎大家建言献策。

    增量下载功能完善：（2022-7-19）

    当前实现思路：因为微信公众号每天只允许发布一篇文章，所以我利用这个限制，取巧地实现了增量更新功能： 每天运行程序，如果发现有新文章，只下载最新的一篇文章就可以了。

    问题所在：如果某天没有运行程序，并且当天有文章A发布，过了几天后又有文章B发布，再运行程序时，只会下载最新的文章B，那么可文章A就错过了。

    解决思路：对比数据库文件和日志文件，不只是为了获取更新状态（即是否有更新），而且要输出更新详细信息：是否更新、更新了哪些文章、这些文章的信息（链接、标题等，可以从 data.txt 数据库文件中提取），然后根据这些详细信息增量下载。


2. ~~定时执行该程序，比如每天执行一次，~~有新文章更新时，~~发邮件~~或者微信通知；

    定时执行功能完善：（2022-7-19）

    目前实现思路：本人 Windows 电脑的定时任务计划功能，更新信息可以通过阅读 更新日志.txt 文件 获知。

    问题所在：（1）如果电脑没有开机或者解锁，那么程序就无法运行；（2）要手动打开 更新日志.txt 文件，将最新日志复制粘贴到微信群中，才能通知。反正总得是主动去查看更新状态，而非主动推送。

    解决思路：上述生成日志文件的思路很好，不需要改变。要改进的是：（1）放到 linux 服务器端定时运行；（2）运行程序更新日志文件后，将最新日志文字自动发送到微信群中~~或者邮件通知~~。

3. ~~查询文章更新状态（简易版），如果未更新则不执行转 pdf 程序，并且通知更新了几篇文章/未更新/删除了几篇文章等信息。~~

    ~~目前思路是比较 data.txt 文档内容来判断更新状态，更简易版是直接比较最新文章的 pos_num 与已转换文章的 pos_num，来判断更新状态。~~

4. 用 pyqt5 封装起来，便于信息输入和转换结果展示；

5. 打包成 .exe 可执行程序，可分发给任何人使用；

6. 多线程，提高采集速度；（目前 50 篇文章大概需要 92秒）

7. 仅提供公众号名称或其他信息，实现自动获取公众号全部合集链接，然后手动选取感兴趣的合集进行下载或者全部下载；


目前的功能我自己用用已经够了，时间有限，不知后续何时抽得出时间来完善。

有兴趣的朋友可以参与进来，一同完成后续改进计划。

